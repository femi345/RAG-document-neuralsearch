services:
  # ── Rust API Server ──
  api:
    build:
      context: .
      dockerfile: rust/Dockerfile
    ports:
      - "8080:8080"
    environment:
      - DATABASE_URL=postgres://cortex:cortex@postgres:5432/cortex
      - WEAVIATE_URL=http://weaviate:8080
      - ML_SERVICE_URL=http://ml:50051
      - HOST=0.0.0.0
      - PORT=8080
      - RUST_LOG=cortex=debug,tower_http=debug
    depends_on:
      postgres:
        condition: service_healthy
      weaviate:
        condition: service_healthy
      ml:
        condition: service_started

  # ── Python ML Service ──
  ml:
    build:
      context: .
      dockerfile: ml/Dockerfile
    ports:
      - "50051:50051"
    environment:
      - EMBEDDING_MODEL=all-MiniLM-L6-v2
      - RERANKER_MODEL=cross-encoder/ms-marco-MiniLM-L-12-v2
      - DEVICE=cpu
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY:-}
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - OLLAMA_HOST=http://ollama:11434
    volumes:
      - model-cache:/root/.cache/huggingface

  # ── PostgreSQL ──
  postgres:
    image: postgres:16-alpine
    ports:
      - "5432:5432"
    environment:
      POSTGRES_USER: cortex
      POSTGRES_PASSWORD: cortex
      POSTGRES_DB: cortex
    volumes:
      - postgres-data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U cortex"]
      interval: 5s
      timeout: 5s
      retries: 5

  # ── Weaviate ──
  weaviate:
    image: cr.weaviate.io/semitechnologies/weaviate:1.28.2
    ports:
      - "8081:8080"
      - "50052:50051"
    environment:
      QUERY_DEFAULTS_LIMIT: 25
      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: "true"
      PERSISTENCE_DATA_PATH: "/var/lib/weaviate"
      ENABLE_MODULES: ""
      DEFAULT_VECTORIZER_MODULE: "none"
      CLUSTER_HOSTNAME: "node1"
    volumes:
      - weaviate-data:/var/lib/weaviate
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:8080/v1/.well-known/ready"]
      interval: 5s
      timeout: 10s
      retries: 5

  # ── Ollama (optional, for local LLM) ──
  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      - ollama-data:/root/.ollama
    profiles:
      - local-llm

volumes:
  postgres-data:
  weaviate-data:
  model-cache:
  ollama-data:
